{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62ec25f0e36346599d100671dcfb8750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51eb5facc1834247afedbaf1b551de2f",
              "IPY_MODEL_3eeda9df126f4a299fba1af84b1d0a56",
              "IPY_MODEL_80cb708011f741bfa1f1d7b18ad15c52"
            ],
            "layout": "IPY_MODEL_d391561052fd44ddb5ad0f36edd63f39"
          }
        },
        "51eb5facc1834247afedbaf1b551de2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e49041267cb49468f44a513d3c7055a",
            "placeholder": "​",
            "style": "IPY_MODEL_ad21dba8be124fc4a5600921f2b982ae",
            "value": "100%"
          }
        },
        "3eeda9df126f4a299fba1af84b1d0a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44dfe92e71b745d38d24b3508dbd1aff",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_553a87d068b246d98f02556d785176b8",
            "value": 14
          }
        },
        "80cb708011f741bfa1f1d7b18ad15c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31145c0d7c41493ebadcbcaff5f98c41",
            "placeholder": "​",
            "style": "IPY_MODEL_8e604f6ed8cf428f8e7e27e252382d1f",
            "value": " 14/14 [00:05&lt;00:00,  2.69ba/s]"
          }
        },
        "d391561052fd44ddb5ad0f36edd63f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e49041267cb49468f44a513d3c7055a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad21dba8be124fc4a5600921f2b982ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44dfe92e71b745d38d24b3508dbd1aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553a87d068b246d98f02556d785176b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31145c0d7c41493ebadcbcaff5f98c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e604f6ed8cf428f8e7e27e252382d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445d37f9b4b448b4926e9e5aac2d8d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2711b1c5acc40a6b4c047b606421d45",
              "IPY_MODEL_98eadbaf33d344438e7a086a8ff3998e",
              "IPY_MODEL_bd7d13db10ca4c86841217c7cd6a23b1"
            ],
            "layout": "IPY_MODEL_0f5a4340a111453996f1629e9d29e4a2"
          }
        },
        "d2711b1c5acc40a6b4c047b606421d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05302a7c819942408a2268ef4d299d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_2b42e8f1d6f54f8fa8245f307f38e4fd",
            "value": "100%"
          }
        },
        "98eadbaf33d344438e7a086a8ff3998e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ddf5af0df94d4881b2715676d452eb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7546a8499b4ac1ae8277bb470025b0",
            "value": 2
          }
        },
        "bd7d13db10ca4c86841217c7cd6a23b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef5b75ca5df4e659f12f3ae951e4e9f",
            "placeholder": "​",
            "style": "IPY_MODEL_5455a3a4c0744c3ca7edf12ab3f23f53",
            "value": " 2/2 [00:00&lt;00:00,  3.17ba/s]"
          }
        },
        "0f5a4340a111453996f1629e9d29e4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05302a7c819942408a2268ef4d299d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b42e8f1d6f54f8fa8245f307f38e4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18ddf5af0df94d4881b2715676d452eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7546a8499b4ac1ae8277bb470025b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ef5b75ca5df4e659f12f3ae951e4e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5455a3a4c0744c3ca7edf12ab3f23f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcSWa436cXMp",
        "outputId": "45575962-fb25-444a-ec87-006dc25b5a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.25.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==2.8.0\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (3.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (0.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (1.21.6)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (21.3)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.8.0) (2022.11.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.8.0) (6.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.8.0) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.8.0) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets==2.8.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.8.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.8.0) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.8.0) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.8.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==2.8.0) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=e41e334e813cc0735e4635115e0c2faeca764c8c91272cb9ed2ddc75c3461b79\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.14.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.13.9\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.25.1\n",
        "!pip install datasets==2.8.0\n",
        "!pip install rouge\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import torch\n",
        "from rouge import Rouge\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    EarlyStoppingCallback\n",
        "\n",
        ")\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "IzAMxPQ1clUS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data(path):\n",
        "\n",
        "    with open(path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    ids = []\n",
        "    dialogues = []\n",
        "    summaries = []\n",
        "    topic = []\n",
        "    for datum in data[\"data\"]:\n",
        "        ids.append(datum[\"header\"][\"dialogueInfo\"][\"dialogueID\"])\n",
        "\n",
        "        prev_speaker_id = None\n",
        "        prev_line = \"\"\n",
        "        utts = []\n",
        "        for dialogue in datum[\"body\"][\"dialogue\"]:\n",
        "            utterance = dialogue[\"utterance\"].strip()\n",
        "\n",
        "            if dialogue[\"participantID\"] == prev_speaker_id:\n",
        "                prev_line += \" \" + utterance\n",
        "            else:\n",
        "                if prev_line:\n",
        "                    utts.append(prev_line)\n",
        "                prev_line = utterance\n",
        "                prev_speaker_id = dialogue[\"participantID\"]\n",
        "        if prev_line:\n",
        "            utts.append(prev_line)\n",
        "\n",
        "        dialogues.append(utts)\n",
        "        summaries.append(datum[\"body\"].get(\"summary\"))\n",
        "\n",
        "    for i in range(len(data['data'])):\n",
        "      topic.append(data['data'][i]['header']['dialogueInfo']['topic'])\n",
        "    return ids[:1555], dialogues[:1555], summaries[:1555], topic[:1555]\n",
        "\n",
        "def data_load(filename, is_meta=False):\n",
        "    ids_list, dialogues_list, summaries_list, topic_list = [], [], [], []\n",
        "    dialogues_sep = []\n",
        "\n",
        "    for file in tqdm(filename):\n",
        "      ids, dialogues, summaries, topic = load_json_data(file)\n",
        "      for id, text, summ, top in zip(ids, dialogues, summaries, topic):\n",
        "        ids_list.append(id)\n",
        "        if is_meta:\n",
        "          text.insert(0,\"#\"+top+\"#\")\n",
        "        dialogues_list.append(text)\n",
        "        summaries_list.append(summ)\n",
        "        topic_list.append(top)\n",
        "    \n",
        "    for text in tqdm(dialogues_list):\n",
        "      dialogues_sep.append(\"[sep]\".join(text))\n",
        "\n",
        "    return ids_list, dialogues_sep, summaries_list\n"
      ],
      "metadata": {
        "id": "W7NkJCnAcoEK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data2(path):\n",
        "\n",
        "    with open(path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    ids = []\n",
        "    dialogues = []\n",
        "    summaries = []\n",
        "    topic = []\n",
        "    for datum in data[\"data\"]:\n",
        "        ids.append(datum[\"header\"][\"dialogueInfo\"][\"dialogueID\"])\n",
        "\n",
        "        prev_speaker_id = None\n",
        "        prev_line = \"\"\n",
        "        utts = []\n",
        "        for dialogue in datum[\"body\"][\"dialogue\"]:\n",
        "            utterance = dialogue[\"utterance\"].strip()\n",
        "\n",
        "            if dialogue[\"participantID\"] == prev_speaker_id:\n",
        "                prev_line += \" \" + utterance\n",
        "            else:\n",
        "                if prev_line:\n",
        "                    utts.append(prev_line)\n",
        "                prev_line = utterance\n",
        "                prev_speaker_id = dialogue[\"participantID\"]\n",
        "        if prev_line:\n",
        "            utts.append(prev_line)\n",
        "\n",
        "        dialogues.append(utts)\n",
        "        summaries.append(datum[\"body\"].get(\"summary\"))\n",
        "\n",
        "    for i in range(len(data['data'])):\n",
        "      topic.append(data['data'][i]['header']['dialogueInfo']['topic'])\n",
        "    return ids[:194], dialogues[:194], summaries[:194], topic[:194]\n",
        "\n",
        "def data_load2(filename, is_meta=False):\n",
        "    ids_list, dialogues_list, summaries_list, topic_list = [], [], [], []\n",
        "    dialogues_sep = []\n",
        "\n",
        "    for file in tqdm(filename):\n",
        "      ids, dialogues, summaries, topic = load_json_data2(file)\n",
        "      for id, text, summ, top in zip(ids, dialogues, summaries, topic):\n",
        "        ids_list.append(id)\n",
        "        if is_meta:\n",
        "          text.insert(0,\"#\"+top+\"#\")\n",
        "        dialogues_list.append(text)\n",
        "        summaries_list.append(summ)\n",
        "        topic_list.append(top)\n",
        "    \n",
        "    for text in tqdm(dialogues_list):\n",
        "      dialogues_sep.append(\"[sep]\".join(text))\n",
        "\n",
        "    return ids_list, dialogues_sep, summaries_list\n"
      ],
      "metadata": {
        "id": "JiTS9NB_c3l1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower() # 텍스트 소문자화\n",
        "    sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+[/ㄱ-ㅎㅏ-ㅣ]', '', sentence) # 여러개 자음과 모음을 삭제한다.\n",
        "    sentence = re.sub(\"[^가-힣a-z0-9#@,-\\[\\]\\(\\)]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
        "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
        "    \n",
        "    return sentence\n",
        "\n",
        "def data_process(data):\n",
        "  # 전체 Text 데이터에 대한 전처리 (1)\n",
        "  text = []\n",
        "\n",
        "  for data_text in tqdm(data):\n",
        "    text.append(preprocess_sentence(data_text))\n",
        "  \n",
        "  return text"
      ],
      "metadata": {
        "id": "t-hghavEc-Yg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = \"/content/drive/MyDrive/인공지능/아이펠톤/PoC/kt_data/Training\"\n",
        "filenames = os.listdir(dirname) \n",
        "train_full_filename = []\n",
        "\n",
        "for filename in filenames:\n",
        "    fn = os.path.join(dirname, filename)\n",
        "    if dirname + '/.ipynb_checkpoints' != fn:\n",
        "        train_full_filename.append(fn)\n",
        "\n",
        "dirname2 = \"/content/drive/MyDrive/인공지능/아이펠톤/PoC/kt_data/Validation\"\n",
        "filenames2 = os.listdir(dirname2) \n",
        "val_full_filename = []\n",
        "\n",
        "for filename in filenames2:\n",
        "    fn2 = os.path.join(dirname2, filename)\n",
        "    if dirname + '/.ipynb_checkpoints' != fn2:\n",
        "        val_full_filename.append(fn2)"
      ],
      "metadata": {
        "id": "HnaNwt42dC8x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids, train_dialogues, train_summaries = data_load(train_full_filename, is_meta=True)\n",
        "val_ids, val_dialogues, val_summaries = data_load2(val_full_filename)\n",
        "\n",
        "train_texts = data_process(train_dialogues)\n",
        "val_texts = data_process(val_dialogues)\n",
        "\n",
        "train_df = pd.DataFrame(zip(train_texts,train_summaries), columns=['Text', 'Summary'])\n",
        "val_df = pd.DataFrame(zip(val_texts,val_summaries), columns=['Text', 'Summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSXlAgAHdDyZ",
        "outputId": "f2f3f271-ca04-4e74-d51f-cf091bfe2746"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:31<00:00,  3.52s/it]\n",
            "100%|██████████| 13995/13995 [00:00<00:00, 917879.07it/s]\n",
            "100%|██████████| 9/9 [00:08<00:00,  1.04it/s]\n",
            "100%|██████████| 1746/1746 [00:00<00:00, 891232.18it/s]\n",
            "100%|██████████| 13995/13995 [00:00<00:00, 45111.48it/s]\n",
            "100%|██████████| 1746/1746 [00:00<00:00, 45783.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "4TOPZUjadOTg",
        "outputId": "8bc87cde-183a-4c72-aa32-2e7fcfa1b7b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  \\\n",
              "0  #상거래(쇼핑)#[sep]그럼 날짜는 가격 큰 변동 없으면 6.28-7.13로 확정...   \n",
              "1  #상거래(쇼핑)#[sep]kf마스크만 5부제 하는거지?[sep]응. 면마스크는 아무...   \n",
              "2  #상거래(쇼핑)#[sep]아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디...   \n",
              "3  #상거래(쇼핑)#[sep]칫솔사야하는데 쓱으로 살까?[sep]뭘 칫솔사는것까지 물어...   \n",
              "4  #상거래(쇼핑)#[sep]잠도안오네 얼릉 고구마츄 먹고싶단[sep]그게 그렇게 맛있...   \n",
              "\n",
              "                                             Summary  \n",
              "0               비행기 표 가격에 대해 이야기하며, 특가 이벤트를 기다리고 있다.  \n",
              "1                비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다.  \n",
              "2  케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...  \n",
              "3            칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계(쓱) 가자고 했다.  \n",
              "4                  잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-644c0315-62ed-414b-8c42-2bae947ed036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#상거래(쇼핑)#[sep]그럼 날짜는 가격 큰 변동 없으면 6.28-7.13로 확정...</td>\n",
              "      <td>비행기 표 가격에 대해 이야기하며, 특가 이벤트를 기다리고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#상거래(쇼핑)#[sep]kf마스크만 5부제 하는거지?[sep]응. 면마스크는 아무...</td>\n",
              "      <td>비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#상거래(쇼핑)#[sep]아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디...</td>\n",
              "      <td>케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#상거래(쇼핑)#[sep]칫솔사야하는데 쓱으로 살까?[sep]뭘 칫솔사는것까지 물어...</td>\n",
              "      <td>칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계(쓱) 가자고 했다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#상거래(쇼핑)#[sep]잠도안오네 얼릉 고구마츄 먹고싶단[sep]그게 그렇게 맛있...</td>\n",
              "      <td>잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-644c0315-62ed-414b-8c42-2bae947ed036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-644c0315-62ed-414b-8c42-2bae947ed036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-644c0315-62ed-414b-8c42-2bae947ed036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF > data Set으로 전환\n",
        "train_data = Dataset.from_pandas(train_df) \n",
        "val_data = Dataset.from_pandas(val_df)\n",
        "test_samples = Dataset.from_pandas(val_df)\n",
        "\n",
        "print(train_data)\n",
        "print(val_data)\n",
        "print(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sk9dvGhdPpo",
        "outputId": "192993f6-46ed-4392-a339-b61d15a256ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Text', 'Summary'],\n",
            "    num_rows: 13995\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Text', 'Summary'],\n",
            "    num_rows: 1746\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Text', 'Summary'],\n",
            "    num_rows: 1746\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoints = \"/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint/domain_adaptation/checkpoint-12500\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)\n",
        "\n",
        "special_words = [\n",
        "                \"#@주소#\", \"#@이모티콘#\", \"#@이름#\", \"#@URL#\", \"#@소속#\",\n",
        "                \"#@기타#\", \"#@전번#\", \"#@계정#\", \"#@url#\", \"#@번호#\", \"#@금융#\", \"#@신원#\",\n",
        "                \"#@장소#\", \"#@시스템#사진#\", \"#@시스템#동영상#\", \"#@시스템#기타#\", \"#@시스템#검색#\",\n",
        "                \"#@시스템#지도#\", \"#@시스템#삭제#\", \"#@시스템#파일#\", \"#@시스템#송금#\", \"#@시스템#\",\n",
        "                \"#개인 및 관계#\", \"#미용과 건강#\", \"#상거래(쇼핑)#\", \"#시사/교육#\", \"#식음료#\", \n",
        "                \"#여가 생활#\", \"#일과 직업#\", \"#주거와 생활#\", \"#행사#\",\"[sep]\"\n",
        "                ]\n",
        "\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\": special_words})\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5peviG3dQUY",
        "outputId": "9d00d321-4a9e-4d57-8eb2-36322566d860"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30032, 768, padding_idx=3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input = 256\n",
        "max_target = 64\n",
        "ignore_index = -100# tokenizer.pad_token_id\n",
        "\n",
        "def add_ignored_data(inputs, max_len, ignore_index):\n",
        "  if len(inputs) < max_len:\n",
        "      pad = [ignore_index] *(max_len - len(inputs)) # ignore_index즉 -100으로 패딩을 만들 것인데 max_len - lne(inpu)\n",
        "      inputs = np.concatenate([inputs, pad])\n",
        "  else:\n",
        "      inputs = inputs[:max_len]\n",
        "\n",
        "  return inputs\n",
        "\n",
        "def add_padding_data(inputs, max_len):\n",
        "    pad_index = tokenizer.pad_token_id\n",
        "    if len(inputs) < max_len:\n",
        "        pad = [pad_index] *(max_len - len(inputs))\n",
        "        inputs = np.concatenate([inputs, pad])\n",
        "    else:\n",
        "        inputs = inputs[:max_len]\n",
        "\n",
        "    return inputs \n",
        "\n",
        "def preprocess_data(data_to_process):\n",
        "    label_id= []\n",
        "    label_ids = []\n",
        "    dec_input_ids = []\n",
        "    input_ids = []\n",
        "    bos = tokenizer('<s>')['input_ids']\n",
        "    for i in range(len(data_to_process['Text'])):\n",
        "        input_ids.append(add_padding_data(tokenizer.encode(data_to_process['Text'][i], add_special_tokens=False), max_input))\n",
        "    for i in range(len(data_to_process['Summary'])):\n",
        "        label_id.append(tokenizer.encode(data_to_process['Summary'][i]))  \n",
        "        label_id[i].append(tokenizer.eos_token_id)   \n",
        "        dec_input_id = bos\n",
        "        dec_input_id += label_id[i][:-1]\n",
        "        dec_input_ids.append(add_padding_data(dec_input_id, max_target))  \n",
        "    for i in range(len(data_to_process['Summary'])):\n",
        "        label_ids.append(add_ignored_data(label_id[i], max_target, ignore_index))\n",
        "   \n",
        "    return {'input_ids': input_ids,\n",
        "            'attention_mask' : (np.array(input_ids) != tokenizer.pad_token_id).astype(int),\n",
        "            'decoder_input_ids': dec_input_ids,\n",
        "            'decoder_attention_mask': (np.array(dec_input_ids) != tokenizer.pad_token_id).astype(int),\n",
        "            'labels': label_ids}\n",
        "\n",
        "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])\n",
        "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "62ec25f0e36346599d100671dcfb8750",
            "51eb5facc1834247afedbaf1b551de2f",
            "3eeda9df126f4a299fba1af84b1d0a56",
            "80cb708011f741bfa1f1d7b18ad15c52",
            "d391561052fd44ddb5ad0f36edd63f39",
            "5e49041267cb49468f44a513d3c7055a",
            "ad21dba8be124fc4a5600921f2b982ae",
            "44dfe92e71b745d38d24b3508dbd1aff",
            "553a87d068b246d98f02556d785176b8",
            "31145c0d7c41493ebadcbcaff5f98c41",
            "8e604f6ed8cf428f8e7e27e252382d1f",
            "445d37f9b4b448b4926e9e5aac2d8d75",
            "d2711b1c5acc40a6b4c047b606421d45",
            "98eadbaf33d344438e7a086a8ff3998e",
            "bd7d13db10ca4c86841217c7cd6a23b1",
            "0f5a4340a111453996f1629e9d29e4a2",
            "05302a7c819942408a2268ef4d299d5d",
            "2b42e8f1d6f54f8fa8245f307f38e4fd",
            "18ddf5af0df94d4881b2715676d452eb",
            "1a7546a8499b4ac1ae8277bb470025b0",
            "4ef5b75ca5df4e659f12f3ae951e4e9f",
            "5455a3a4c0744c3ca7edf12ab3f23f53"
          ]
        },
        "id": "_vfFgTe5dhtJ",
        "outputId": "8e405b37-78c4-456f-8377-72977c6828cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62ec25f0e36346599d100671dcfb8750"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "445d37f9b4b448b4926e9e5aac2d8d75"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "    \n",
        "    return rouge.get_scores(pred_str, label_str, avg=True)   "
      ],
      "metadata": {
        "id": "1H4k62TdeBt5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.max_length = 64 \n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 5\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft\",\n",
        "    num_train_epochs=5,  # demo\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=128,  # demo\n",
        "    per_device_eval_batch_size=256,\n",
        "    learning_rate=3e-05,\n",
        "    weight_decay=0.1,\n",
        "    #label_smoothing_factor=0.1,\n",
        "    predict_with_generate=True, # 생성기능을 사용하고 싶다고 지정한다.\n",
        "    logging_dir=\"/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/logs2\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end = True,\n",
        "    logging_strategy = 'epoch',\n",
        "    evaluation_strategy  = 'epoch',\n",
        "    save_strategy ='epoch',\n",
        ")"
      ],
      "metadata": {
        "id": "K29d_fdBeCsF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) # 데이터 일괄 처리?\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model, \n",
        "    training_args,\n",
        "    train_dataset=train_tokenize_data,\n",
        "    eval_dataset=val_tokenize_data,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n3Kl0rNGeLLY",
        "outputId": "fa8943bf-bdaa-469d-cf09-2fa7e97915f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13995\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 550\n",
            "  Number of trainable parameters = 123884544\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230125_070244-14b3zclq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/14b3zclq\" target=\"_blank\">/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">https://wandb.ai/jx7789/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/jx7789/huggingface/runs/14b3zclq\" target=\"_blank\">https://wandb.ai/jx7789/huggingface/runs/14b3zclq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/550 18:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge-1</th>\n",
              "      <th>Rouge-2</th>\n",
              "      <th>Rouge-l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.852900</td>\n",
              "      <td>2.282979</td>\n",
              "      <td>{'r': 0.20870334940866161, 'p': 0.22574141332224712, 'f': 0.20968642204565263}</td>\n",
              "      <td>{'r': 0.07469158408605986, 'p': 0.08094631507439717, 'f': 0.07462300103765918}</td>\n",
              "      <td>{'r': 0.19890703810324445, 'p': 0.21530447993579893, 'f': 0.19987447466175248}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.187600</td>\n",
              "      <td>2.231880</td>\n",
              "      <td>{'r': 0.22810406925311497, 'p': 0.229448748303972, 'f': 0.22149204757876712}</td>\n",
              "      <td>{'r': 0.08594435584174136, 'p': 0.08649026114492554, 'f': 0.08306646746281814}</td>\n",
              "      <td>{'r': 0.21715374924689126, 'p': 0.21859347051236708, 'f': 0.21088582957265045}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.020100</td>\n",
              "      <td>2.205199</td>\n",
              "      <td>{'r': 0.23327182705080635, 'p': 0.23495003214505528, 'f': 0.2263587255011518}</td>\n",
              "      <td>{'r': 0.0874382720562843, 'p': 0.08917472535575753, 'f': 0.08485724416834559}</td>\n",
              "      <td>{'r': 0.22169037841217523, 'p': 0.22341220403166476, 'f': 0.21515133328400535}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.910100</td>\n",
              "      <td>2.199714</td>\n",
              "      <td>{'r': 0.23418463242350396, 'p': 0.23548265971047777, 'f': 0.22738987602083843}</td>\n",
              "      <td>{'r': 0.08717310546397102, 'p': 0.08821211748909066, 'f': 0.08445225315382081}</td>\n",
              "      <td>{'r': 0.22232527257056703, 'p': 0.22372248429110708, 'f': 0.2159174890798592}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.847000</td>\n",
              "      <td>2.205849</td>\n",
              "      <td>{'r': 0.239660992472629, 'p': 0.23651147363839803, 'f': 0.23056261109808704}</td>\n",
              "      <td>{'r': 0.09039746726550081, 'p': 0.09022180754061271, 'f': 0.08693488223798096}</td>\n",
              "      <td>{'r': 0.22742417000428333, 'p': 0.2246443100774873, 'f': 0.21886646221602946}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1746\n",
            "  Batch size = 256\n",
            "Trainer is attempting to log a value of \"{'r': 0.20870334940866161, 'p': 0.22574141332224712, 'f': 0.20968642204565263}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.07469158408605986, 'p': 0.08094631507439717, 'f': 0.07462300103765918}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.19890703810324445, 'p': 0.21530447993579893, 'f': 0.19987447466175248}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110\n",
            "Configuration saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110/config.json\n",
            "Model weights saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1746\n",
            "  Batch size = 256\n",
            "Trainer is attempting to log a value of \"{'r': 0.22810406925311497, 'p': 0.229448748303972, 'f': 0.22149204757876712}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.08594435584174136, 'p': 0.08649026114492554, 'f': 0.08306646746281814}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.21715374924689126, 'p': 0.21859347051236708, 'f': 0.21088582957265045}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220\n",
            "Configuration saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220/config.json\n",
            "Model weights saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1746\n",
            "  Batch size = 256\n",
            "Trainer is attempting to log a value of \"{'r': 0.23327182705080635, 'p': 0.23495003214505528, 'f': 0.2263587255011518}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.0874382720562843, 'p': 0.08917472535575753, 'f': 0.08485724416834559}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.22169037841217523, 'p': 0.22341220403166476, 'f': 0.21515133328400535}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-330\n",
            "Configuration saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-330/config.json\n",
            "Model weights saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-330/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-330/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-330/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1746\n",
            "  Batch size = 256\n",
            "Trainer is attempting to log a value of \"{'r': 0.23418463242350396, 'p': 0.23548265971047777, 'f': 0.22738987602083843}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.08717310546397102, 'p': 0.08821211748909066, 'f': 0.08445225315382081}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.22232527257056703, 'p': 0.22372248429110708, 'f': 0.2159174890798592}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440\n",
            "Configuration saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440/config.json\n",
            "Model weights saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-110] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1746\n",
            "  Batch size = 256\n",
            "Trainer is attempting to log a value of \"{'r': 0.239660992472629, 'p': 0.23651147363839803, 'f': 0.23056261109808704}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.09039746726550081, 'p': 0.09022180754061271, 'f': 0.08693488223798096}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'r': 0.22742417000428333, 'p': 0.2246443100774873, 'f': 0.21886646221602946}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550\n",
            "Configuration saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550/config.json\n",
            "Model weights saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-550/special_tokens_map.json\n",
            "Deleting older checkpoint [/content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-220] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/인공지능/생성요약프로젝트/Model/KoBART/checkpoint2/domain_adaptation_ft/checkpoint-440 (score: 2.199713706970215).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=550, training_loss=2.163542841131037, metrics={'train_runtime': 1129.6836, 'train_samples_per_second': 61.942, 'train_steps_per_second': 0.487, 'total_flos': 1.0666577166336e+16, 'train_loss': 2.163542841131037, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAOgBA59eM5g"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}